# EMOPIA: AI-Powered Emotion-Based Music Generation System
## Complete Project Report

**Jaypee Institute of Information Technology, Noida**

---

## TABLE OF CONTENTS

### Preliminary Pages
- Cover Page
- Declaration
- Certificate
- Acknowledgement
- Summary (250 words)
- List of Figures
- List of Tables
- List of Symbols & Acronyms

### Main Content
1. **Introduction**
   - 1.1 General Introduction
   - 1.2 Problem Statement
   - 1.3 Significance/Novelty
   - 1.4 Empirical Study
   - 1.5 Solution Approach
   - 1.6 Comparison of Approaches

2. **Literature Survey**
   - 2.1 Summary of Papers
   - 2.2 Integrated Summary

3. **Requirement Analysis**
   - 3.1 Overall Description
   - 3.2 Functional/Non-Functional Requirements
   - 3.5 Solution Approach

4. **Modeling and Implementation**
   - 4.1 Design Diagrams
   - 4.2 Implementation Details
   - 4.3 Risk Analysis

5. **Testing**
   - 5.1 Testing Plan
   - 5.2 Component Decomposition
   - 5.3 Test Cases
   - 5.4 Error Handling
   - 5.5 Limitations

6. **Findings, Conclusion, Future Work**
   - 6.1 Findings
   - 6.2 Conclusion
   - 6.3 Future Work

### References
### Student Bio-data

---

## EXECUTIVE SUMMARY

**Project Title**: EMOPIA - AI-Powered Emotion-Based Music Generation System

**Objective**: Develop an intelligent system that generates emotionally expressive music using deep learning, specifically Transformer architecture conditioned on emotion labels.

**Key Achievements**:
- Implemented 6-layer Transformer model with 50M parameters
- Trained on 1,078 emotion-labeled MIDI files
- Achieved validation loss of 1.8154 after 24 epochs
- Developed full-stack application (React + Flask + PyTorch)
- Integrated RL fine-tuning with human feedback
- Generated coherent 2-3 minute musical compositions

**Technologies**: PyTorch, Transformers, Flask, React, MIDI Processing, Reinforcement Learning

**Impact**: Democratizes music creation, enables emotion-specific composition, supports creative industries

---

